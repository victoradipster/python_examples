# **Finding Lane Lines on the Road Writeup Template**

## Writeup Template
----

**Term 1-Project 1: Finding Lane Lines on the Road**
The main goal of this project is to uniquely identify two boarder lane lines on your your driving tract first on a set of images and then later on a video stream:

### 1. How this project pipeline has been built.
* A great starting point to building this project is to have an understanding of [image basics](https://mmeysenburg.github.io/image-processing/02-image-basics/), how [OpenCV] does image processing, what a pixel really is, how digital image is reprenting and the Left-Hand Coordinate system.A great documentation on all of these starting concepts can be found [here](https://mmeysenburg.github.io/image-processing/04-drawing-bitwise/) and even [image thresholding](https://mmeysenburg.github.io/image-processing/07-thresholding/). To play with colors or obtain values corresponding to different color values, you can check that out [here](https://www.rapidtables.com/web/color/RGB_Color.html)
* With all of that done, we can get started with this project.First of all, all necessary libraries are imported.
* we read-in or input our sample image frame image = mpimg.imread('test_images/solidWhiteRight.jpg') and the print some statistics about the image(image type and dimensions)
* Secondly, we need to grayscale this image by(). This is to lesson the burden on the processor which is a very scare resource on embeded systems.This also helps execute the project faster with less resources. We will now do all image processing on the grayscale image instead of the original version of the image. 
* Next, we will remove noise from our image by blurring it.Image blurring is achieved by convolving the image with a low pass-filter kernel.It actually removes high frequency content(eg noise,edges) from the image. OpenCV provides about 4 different types of blurring techniques with [Guassian blur] being the most popular one.We can select different kernel sizes, wherein the resultant filter will simply take the average of all the pixels under kernel (a row x column matrix of kernel size) area and replace the central element with average value(5 is a fairly standard value for kernel size)
* Now, we apply Canny edge detection to filtered image.The basic theory behind edge detection is, wherever there is an edge(Think of an edge here as a transition from a certain color intensity as a transition from a certain color intensity to another.Call it up/down jumps in color intensity valuesin the image if you like.), the pixel on either side of the edge have a big difference (also called gradient) between their intensities.First the input image is scanned in both horizontal and vertical direction to find gradient for each pixel. After getting gradient magnitude and direction(think of gradient here as a change in pixel intensity,magnitude as how big this change is and direction as to whether this change is from a high to a low intensity value or vice versa),a full scan of image is done to remove any unwanted pixels which may not constitute the edge.This brings us to setting `low_threshold` and `high_threshold` to determine how strong the edge must be to be detected
* With reference to our sample image, it’s clear that at edge conditions, especially where lane lines are, there is vast contrast difference between adjacent pixels, with lane line being white and adjacent road pixel being dark.One thing to consider is, we don’t want to find all the edges in the image. We are just interested in finding the lane around the center area of our image. Intuitively it makes sense as in an edge in top right / left portion of the image is highly unlikely to be a driving lane. Looking at out sample image, we can safely say that lane lines should be inside a trapezoidal area with broader edge at bottom of image and with edges becoming narrower as we go towards top(y_size/2) portion of the image.Following this, we will need to mark out four vertices(bottom_left,top_left,top_right and botoom_right) to represent the corners of our trapezium(region of interest).This step, as many others is bit of an iterative process, wherein we need to try with different values to find out best case.Preferably, it's better to define your border coners (bottom_left,top_left,top_right and botoom_right) for region of interest as dynamically by y_size/x_size multiplied by a given factor say 0.5 for example instead of just just defining a given corner as (460,310). This because the program may require at sometime to process images which are of different sizes as opposed to the initial images you used in defining such a point(460,310).From initial starter code on the `region_of_interest` function, I didn't really understand what the following lines
    ```if len(image.shape) > 2:
        channel_count = image.shape[2]   i.e. 3 or 4 depending on your image
        ignore_mask_color = (255,) * channel_count
     else:
         ignore_mask_color = 255``` 
had to do as far as what this function is suppose to do but with my uderstanding of what this function is doing, I had to modify it as can be seen on the code.
* Moving forward to the `draw_lines` function turns out to me like there are actually several ways one could go about inoreder to achieve this. However, I went with the simplest implementation. My ideas all came from the equation of a slanting straight line equation of `y=mx+b` and knowing how the **left-hand coordinate system** is, we should understand that our left lane line will have a **negative slope** while the right lane line will have a **positive slope** and so, lines will be separated based on the **sign** of their slope(m). For each line, I created two lists to hold **slope(m) values** and another one to hold **intercept(b) values**.I then get a single average value for all slope values on the slope list and another single b value for all b generated values. This is done by calling the `mean` function which I defined. To draw an average line on each of the lanes, we need **four interger(int) values(x1,y1,x2,y2)** to pass as parameters to the `cv2.line()` function.Looking at the image, our **y1,y2 values** can be explicitly defined for each lane while putting **notion of region of interest** in mind.To get **x1,x2** values for each line, we need to make **x** the subject of the **y=mx+b equation**. So replacing **y** with **y1**, we get **x1** and with **y2**, we get **x2**. Notice that we need **m and b values** in this **y=mx+b**.Rememberthat we have had **left lane m and b values** separated from those of the right lane and **computed an average value for each** which we now fit into this **y=mx+b equation** in order to get our **x1,x2 values** for each of the lane lines.
* Next we perform Hough Line Transform in order to detect a line from the above edge detected image. Hough’s transform method transforms a line from its traditional `y = mx + b` form to `rho = x *cos (theta) + y * sin (theta)` where rho is the perpendicular distance from origin to the line, and theta is the angle formed by this perpendicular line and horizontal axis. A line (y = mx + b) when represented in m vs b graph is just a point, and a point in x, y frame is represented as a line in m vs b frame. For information relating houghtransform and x-y coordinate system, checkout [here](http://aishack.in/tutorials/hough-transform-basics/). 

We know that a line (y = mx + b) when represented in m vs b graph is just a point, and a point in x, y frame is represented as a line in m vs b frame. So our strategy to find lines in image space will be to find intersecting lines in Hough space. We do this by dividing up our Hough space into a grid and define intersecting lines as all lines passing through a given grid cell. And where many lines in Hough space intersect, we declare we have found a collection of points that describe a line in image space.I also define parameters for that the `hough_lines` function will take at function call.
    ```rho = 1 # distance resolution in pixels of the Hough grid
theta = np.pi/180 # angular resolution in radians of the Hough grid
threshold = 15     # minimum number of votes (intersections in Hough grid cell)
min_line_length = 40 #minimum number of pixels making up a line
max_line_gap = 30    # maximum gap in pixels between connectable line segments```
These values are not standard values. They should be tuned iteratively to get average best performing values
* There's also the `process_img` function which takes an image as it's argument and and apply all the functions we've discusses so far in an orderly manner.

###  Potentential shortcoming to this pipeline
* One shortcoming is that the pipeline may fail to correctly mark out lane lines on a bendy road scenario.

### A possible improvements to the pipeline
* One possible improvement to make to make the pipeline improve it's lane marking capabilities on a bendy road could be to tune and iteratively increase the y-coordinate-values for the region of interest. This will reduce the height of the region of interest. 
